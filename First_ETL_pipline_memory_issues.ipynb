{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA Airlines analysis By [BTS](https://transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) \n",
    "\n",
    "### Introduction\n",
    "\n",
    "The United States Department of Transportation has Flight Stats available through the Bureau of Transportation Statistics.\n",
    "This data comes from The Bureau of Transportation Statistics and tracks destinations, distance, and delay information of flights across U.S. For this project, I chose the years **1995** through **February 2020** \n",
    "\n",
    "### Notes\n",
    "\n",
    "Throughout this notebook, you'll notice that most operations are single cell, this was because my machine kept running out of usable memory. The dataset was really large and required as much memory as possible for each operation. You will see multiple cells of code that could possibly be more code efficient, but were lengthened to reduce memory errors. You will also notice that after certain blocks of code, I outputted the dataframe to a csv. Some blocks of code took more than an hour to run. So to save my progress and make sure that I would not waste time re-running previous code, I would output my progress to a csv and then read it back in. I did not include these datasets in the repository, but have kept the code in the notebook.\n",
    "\n",
    "The BTS website did not allow users to download full years of data. I downloaded data from the BTS website month by month from **1995 to February 2020*** and then used pandas to merge the data together.after cleaning each Csv  file then save it back to another csv to reduce memory usage and drop unnessasry columns in this **Gigantic** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline Preparation\n",
    "Follow the instructions below to help you create your ETL pipeline.\n",
    "### 1. Import libraries and load datasets.\n",
    "- Import Python libraries\n",
    "- Load `2019_1.csv` into a dataframe and inspect the first few lines. this CSV file contains data for all airports for the period 1-1-2019 till 31-1-2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlite3 as slq\n",
    "import math\n",
    "import datetime\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load january 2019 dataset\n",
    "df1=pd.read_csv(r\"D:\\on time data for airlines\\2019\\2019_1.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>DOT_ID_Reporting_Airline</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Div4TailNum</th>\n",
       "      <th>Div5Airport</th>\n",
       "      <th>Div5AirportID</th>\n",
       "      <th>Div5AirportSeqID</th>\n",
       "      <th>Div5WheelsOn</th>\n",
       "      <th>Div5TotalGTime</th>\n",
       "      <th>Div5LongestGTime</th>\n",
       "      <th>Div5WheelsOff</th>\n",
       "      <th>Div5TailNum</th>\n",
       "      <th>Unnamed: 109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>OO</td>\n",
       "      <td>20304</td>\n",
       "      <td>OO</td>\n",
       "      <td>N945SW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>OO</td>\n",
       "      <td>20304</td>\n",
       "      <td>OO</td>\n",
       "      <td>N932SW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>OO</td>\n",
       "      <td>20304</td>\n",
       "      <td>OO</td>\n",
       "      <td>N932SW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>OO</td>\n",
       "      <td>20304</td>\n",
       "      <td>OO</td>\n",
       "      <td>N916SW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>OO</td>\n",
       "      <td>20304</td>\n",
       "      <td>OO</td>\n",
       "      <td>N107SY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
       "0  2019        1      1           4          5  2019-01-04                OO   \n",
       "1  2019        1      1           4          5  2019-01-04                OO   \n",
       "2  2019        1      1           4          5  2019-01-04                OO   \n",
       "3  2019        1      1           4          5  2019-01-04                OO   \n",
       "4  2019        1      1           4          5  2019-01-04                OO   \n",
       "\n",
       "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
       "0                     20304                          OO      N945SW  ...   \n",
       "1                     20304                          OO      N932SW  ...   \n",
       "2                     20304                          OO      N932SW  ...   \n",
       "3                     20304                          OO      N916SW  ...   \n",
       "4                     20304                          OO      N107SY  ...   \n",
       "\n",
       "   Div4TailNum  Div5Airport  Div5AirportID  Div5AirportSeqID Div5WheelsOn  \\\n",
       "0          NaN          NaN            NaN               NaN          NaN   \n",
       "1          NaN          NaN            NaN               NaN          NaN   \n",
       "2          NaN          NaN            NaN               NaN          NaN   \n",
       "3          NaN          NaN            NaN               NaN          NaN   \n",
       "4          NaN          NaN            NaN               NaN          NaN   \n",
       "\n",
       "  Div5TotalGTime Div5LongestGTime  Div5WheelsOff Div5TailNum  Unnamed: 109  \n",
       "0            NaN              NaN            NaN         NaN           NaN  \n",
       "1            NaN              NaN            NaN         NaN           NaN  \n",
       "2            NaN              NaN            NaN         NaN           NaN  \n",
       "3            NaN              NaN            NaN         NaN           NaN  \n",
       "4            NaN              NaN            NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 110 entries, Year to Unnamed: 109\n",
      "dtypes: float64(69), int64(21), object(20)\n",
      "memory usage: 490.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_1\n",
    "Due to high data load this file only which contain just one month data uses **490 MB** so let's munge our data and keep necessary columns only to decrease or eliminate this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory size issue\n",
    "\n",
    "it's clear that after we have run this single month data for 2019 we use about **500 MB** of memory so what about data soan from 2020 to 1995 so about 25 years of data each year has 12 csv file so let's overcome this problem.\n",
    "\n",
    "### Soluntions\n",
    "\n",
    "1- Fisrt thing i will drop all unrelevant columns or columns provide unuseful information for my analysis \n",
    "\n",
    "2- I will invastigate all columns to find ranges of numerical data then i will downcast it to proper data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : remove Unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-necessary Data for our analysis\n",
    "\n",
    "We are not interested in further information about more than one **DIVERTED airport** so i will drop theses columns furthermore these columns contain almot 100% Nan values beacuse amot all flights didn't need diverted airport or at most only one diverted Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diverted_cols = ['Div2Airport','Div2AirportID','Div2AirportSeqID','Div2WheelsOn','Div2TotalGTime',\n",
    " 'Div2LongestGTime','Div2WheelsOff','Div2TailNum','Div3Airport','Div3AirportID','Div3AirportSeqID',\n",
    " 'Div3WheelsOn','Div3TotalGTime','Div3LongestGTime','Div3WheelsOff','Div3TailNum','Div4Airport',\n",
    " 'Div4AirportID','Div4AirportSeqID','Div4WheelsOn','Div4TotalGTime','Div4LongestGTime','Div4WheelsOff',\n",
    " 'Div4TailNum','Div5Airport','Div5AirportID','Div5AirportSeqID','Div5WheelsOn','Div5TotalGTime',\n",
    " 'Div5LongestGTime','Div5WheelsOff','Div5TailNum','Unnamed: 109']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(Diverted_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 77 entries, Year to Div1TailNum\n",
      "dtypes: float64(39), int64(21), object(17)\n",
      "memory usage: 343.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_2\n",
    "After removing unnecessary data which describe the Second,third,fourth and fifth diverted airport we decreased memory usage by **26.85%** which becomes **343.1 MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redundant columns\n",
    "the follwing columns are repeted or contain information that not necessary or repetead in another form in another columns so i will drop it for memory issues \n",
    "\n",
    "`'DOT_ID_Reporting_Airline'`          didn't provide useful info \n",
    "\n",
    "`'IATA_CODE_Reporting_Airline'`       i will use **Reporting_Airline** column instead\n",
    "\n",
    "`'OriginAirportSeqID'`                i will use **OriginAirportID** as this column is unique for each airport over the years\n",
    "\n",
    "`'OriginStateFips'`                   this column contain fedral identfication number for each airport \n",
    "\n",
    "`'OriginState'`                       **OriginStateName** column in more handy\n",
    "\n",
    "`'OriginWac'`                         origin area code is not helpful for my analysis\n",
    "\n",
    "`'DestAirportSeqID'`                  i will use **DestAirportID** as this column is unique for each airport over the years\n",
    "\n",
    "`'DestState'`                         **DestStateName** column in more handy\n",
    "\n",
    "`'DestStateFips'`                     this column contain fedral identfication number for each airport \n",
    "\n",
    "`'DestWac'`                           Destination area code is not helpful for my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrelevant columns\n",
    "\n",
    "unrelevant_col = ['DOT_ID_Reporting_Airline',\n",
    "                  'IATA_CODE_Reporting_Airline',\n",
    "                  'OriginAirportSeqID',\n",
    "                  'OriginStateFips',\n",
    "                  'OriginState',\n",
    "                  'OriginWac',\n",
    "                  'DestAirportSeqID',\n",
    "                  'DestState',\n",
    "                  'DestStateFips',\n",
    "                  'Div1WheelsOff',                     \n",
    "                  'Div1TailNum',\n",
    "                  'Div1AirportSeqID',\n",
    "                  'DestWac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1.drop(unrelevant_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: float64(37), int64(14), object(13)\n",
      "memory usage: 285.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_3\n",
    "After removing Redundant columns we decreased memory usage by **17%** which becomes **285.1 MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Datatypes Downcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Quarter',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'Flight_Number_Reporting_Airline',\n",
       " 'OriginAirportID',\n",
       " 'OriginCityMarketID',\n",
       " 'DestAirportID',\n",
       " 'DestCityMarketID',\n",
       " 'CRSDepTime',\n",
       " 'CRSArrTime',\n",
       " 'DistanceGroup',\n",
       " 'DivAirportLandings']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(df1.select_dtypes('int64').columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining each column and apply pandas.dataframe.describe() method to find statistics about each column its min and max specially to find ranges and which of them fit with **int16** and we find that all of thes columns fit wih **int16** except `'Flight_Number_Reporting_Airline'` \n",
    "\n",
    "as we know int16 uses 2 bytes of data while **int64** uses 8 bytes of data by this technique we will save alot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_downcast=['Year',\n",
    " 'Quarter',\n",
    " 'Month',\n",
    " 'DayofMonth',\n",
    " 'DayOfWeek',\n",
    " 'OriginAirportID',\n",
    " 'DestAirportID',\n",
    " 'DistanceGroup',\n",
    " 'DivAirportLandings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[int_downcast]=df1[int_downcast].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: float64(37), int16(9), int64(5), object(13)\n",
      "memory usage: 255.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_4\n",
    "After downcasting **int64** columns which can fit with **int16** we decreased memory usage from **285.1 MB** by **14.7%** which becomes **248.4 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DepTime',\n",
       " 'DepDelay',\n",
       " 'DepDelayMinutes',\n",
       " 'DepDel15',\n",
       " 'DepartureDelayGroups',\n",
       " 'TaxiOut',\n",
       " 'WheelsOff',\n",
       " 'WheelsOn',\n",
       " 'TaxiIn',\n",
       " 'ArrTime',\n",
       " 'ArrDelay',\n",
       " 'ArrDelayMinutes',\n",
       " 'ArrDel15',\n",
       " 'ArrivalDelayGroups',\n",
       " 'Cancelled',\n",
       " 'Diverted',\n",
       " 'CRSElapsedTime',\n",
       " 'ActualElapsedTime',\n",
       " 'AirTime',\n",
       " 'Flights',\n",
       " 'Distance',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay',\n",
       " 'FirstDepTime',\n",
       " 'TotalAddGTime',\n",
       " 'LongestAddGTime',\n",
       " 'DivReachedDest',\n",
       " 'DivActualElapsedTime',\n",
       " 'DivArrDelay',\n",
       " 'DivDistance',\n",
       " 'Div1AirportID',\n",
       " 'Div1WheelsOn',\n",
       " 'Div1TotalGTime',\n",
       " 'Div1LongestGTime']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(df1.select_dtypes('float64').columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_downcast=['Distance',\n",
    " 'CarrierDelay',\n",
    " 'WeatherDelay',\n",
    " 'NASDelay',\n",
    " 'SecurityDelay',\n",
    " 'LateAircraftDelay',\n",
    " 'DivArrDelay',\n",
    " 'DivDistance','Div1TotalGTime',\n",
    " 'Div1LongestGTime',\n",
    " 'Div1AirportID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First \n",
    "\n",
    "`'Flights'` can be converted to int8\n",
    "\n",
    "##### Second\n",
    " **`'Distance','CarrierDelay','WeatherDelay','NASDelay'`,**\n",
    " \n",
    "**`'SecurityDelay','LateAircraftDelay','DivArrDelay','DivDistance'`,**\n",
    " \n",
    " **`'Div1TotalGTime','Div1LongestGTime'`**\n",
    " \n",
    "**can be converted to float16 as the range for theire values between -32768 and 32767**\n",
    "\n",
    "other columns like \n",
    "**`'DepDel15','ArrDel15','Cancelled','Diverted','DivReachedDest'`** are ust an **indicator** 0,1 so i will convert them into **Boolean** in the next step after converting the previous columns into **float16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Flights']=df1['Flights'].astype('int8')\n",
    "\n",
    "df1[float_downcast]=df1[float_downcast].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: float16(11), float64(25), int16(9), int64(5), int8(1), object(13)\n",
      "memory usage: 214.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_4\n",
    "After downcasting **float64** columns which can fit with **float16** we decreased memory usage from **248.4 MB** by **15%** which becomes **211.1 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_downcast=['DepDel15','ArrDel15','Cancelled','Diverted','DivReachedDest']\n",
    "\n",
    "df1[bool_downcast]=df1[bool_downcast].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), float16(11), float64(20), int16(9), int64(5), int8(1), object(13)\n",
      "memory usage: 194.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory usage_5\n",
    "After downcasting **some of float64** columns which are just an indicator into **bool** we decreased memory usage from **211.1 MB** by **9.24%** which becomes **191.6 MB**\n",
    "\n",
    "After that we still have 4 columns their dtypes are **int64** while we can convert them into **int32** to save more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flight_Number_Reporting_Airline',\n",
       " 'OriginCityMarketID',\n",
       " 'DestCityMarketID',\n",
       " 'CRSDepTime',\n",
       " 'CRSArrTime']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_downcast_32=list(df1.select_dtypes('int64').columns)\n",
    "int_downcast_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[int_downcast_32]=df1[int_downcast_32].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), float16(11), float64(20), int16(9), int32(5), int8(1), object(13)\n",
      "memory usage: 183.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DepTime',\n",
       " 'DepDelay',\n",
       " 'DepDelayMinutes',\n",
       " 'DepartureDelayGroups',\n",
       " 'TaxiOut',\n",
       " 'WheelsOff',\n",
       " 'WheelsOn',\n",
       " 'TaxiIn',\n",
       " 'ArrTime',\n",
       " 'ArrDelay',\n",
       " 'ArrDelayMinutes',\n",
       " 'ArrivalDelayGroups',\n",
       " 'CRSElapsedTime',\n",
       " 'ActualElapsedTime',\n",
       " 'AirTime',\n",
       " 'FirstDepTime',\n",
       " 'TotalAddGTime',\n",
       " 'LongestAddGTime',\n",
       " 'DivActualElapsedTime',\n",
       " 'Div1WheelsOn']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(df1.select_dtypes('float64').columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_downcast=['DepartureDelayGroups','ArrivalDelayGroups','DistanceGroup']\n",
    "df1[categorical_downcast]=df1[categorical_downcast].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), category(3), float16(11), float64(18), int16(8), int32(5), int8(1), object(13)\n",
      "memory usage: 175.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time and date columns in float64 Format\n",
    "\n",
    "we can observe that each ne of the previous **18** columns describe date or time information and after investigating their range all of them can fit into **float16** format this is a transitional step before converting them into approprite **datetime** format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_float_downcast=['DepTime',\n",
    " 'DepDelay',\n",
    " 'DepDelayMinutes',\n",
    " 'TaxiOut',\n",
    " 'WheelsOff',\n",
    " 'WheelsOn',\n",
    " 'TaxiIn',\n",
    " 'ArrTime',\n",
    " 'ArrDelay',\n",
    " 'ArrDelayMinutes',\n",
    " 'CRSElapsedTime',\n",
    " 'ActualElapsedTime',\n",
    " 'AirTime',\n",
    " 'FirstDepTime',\n",
    " 'TotalAddGTime',\n",
    " 'LongestAddGTime',\n",
    " 'DivActualElapsedTime',\n",
    " 'Div1WheelsOn',\n",
    " 'CRSArrTime', 'CRSDepTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[time_float_downcast]=df1[time_float_downcast].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583985 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), category(3), float16(31), int16(8), int32(3), int8(1), object(13)\n",
      "memory usage: 113.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhmm columns in our dataframe\n",
    "hhmm=['DepTime',\n",
    "      'CRSArrTime', \n",
    "      'CRSDepTime',\n",
    "      'WheelsOff',\n",
    "      'WheelsOn','ArrTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna(subset=hhmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566924, 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 566924 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), category(3), float16(31), int16(8), int32(3), int8(1), object(13)\n",
      "memory usage: 114.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_time_1(col):\n",
    "\n",
    "    Hours = int(col / 100)\n",
    "    Minute = round(float(col/ 100) - Hours,2)\n",
    "    Hours = str(int(Hours)).zfill(2)\n",
    "    Minute = str(Minute).replace('0.','').zfill(2)\n",
    "    my_str = Hours+':'+Minute\n",
    "    \n",
    "    return my_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hhmm:\n",
    "    df1[i]=df1[i].apply(lambda x:std_time_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hhmm:\n",
    "    df1[i]=df1[i].str.replace('24:00','23:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_time(string):\n",
    "    return datetime.datetime.strptime(string, '%H:%M').time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_time_2(string):\n",
    "    \n",
    "    return datetime.time.strptime(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hhmm:\n",
    "    df1[i]=df1[i].apply(lambda x:std_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>WheelsOff</th>\n",
       "      <th>WheelsOn</th>\n",
       "      <th>ArrTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13:53:00</td>\n",
       "      <td>15:01:00</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>14:02:00</td>\n",
       "      <td>14:39:00</td>\n",
       "      <td>14:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:03:00</td>\n",
       "      <td>11:18:00</td>\n",
       "      <td>09:35:00</td>\n",
       "      <td>09:57:00</td>\n",
       "      <td>11:13:00</td>\n",
       "      <td>11:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06:37:00</td>\n",
       "      <td>08:55:00</td>\n",
       "      <td>06:43:00</td>\n",
       "      <td>06:54:00</td>\n",
       "      <td>08:22:00</td>\n",
       "      <td>08:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13:14:00</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>13:35:00</td>\n",
       "      <td>13:37:00</td>\n",
       "      <td>13:57:00</td>\n",
       "      <td>14:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08:26:00</td>\n",
       "      <td>10:04:00</td>\n",
       "      <td>08:36:00</td>\n",
       "      <td>08:52:00</td>\n",
       "      <td>09:59:00</td>\n",
       "      <td>10:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16:00:00</td>\n",
       "      <td>18:26:00</td>\n",
       "      <td>16:01:00</td>\n",
       "      <td>16:21:00</td>\n",
       "      <td>18:11:00</td>\n",
       "      <td>18:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16:14:00</td>\n",
       "      <td>18:56:00</td>\n",
       "      <td>16:15:00</td>\n",
       "      <td>16:43:00</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>18:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10:53:00</td>\n",
       "      <td>12:04:00</td>\n",
       "      <td>10:45:00</td>\n",
       "      <td>11:07:00</td>\n",
       "      <td>12:18:00</td>\n",
       "      <td>12:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>06:24:00</td>\n",
       "      <td>07:51:00</td>\n",
       "      <td>06:37:00</td>\n",
       "      <td>07:08:00</td>\n",
       "      <td>07:45:00</td>\n",
       "      <td>07:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>07:59:00</td>\n",
       "      <td>11:07:00</td>\n",
       "      <td>08:03:00</td>\n",
       "      <td>08:18:00</td>\n",
       "      <td>10:53:00</td>\n",
       "      <td>11:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15:41:00</td>\n",
       "      <td>17:03:00</td>\n",
       "      <td>15:36:00</td>\n",
       "      <td>15:53:00</td>\n",
       "      <td>16:51:00</td>\n",
       "      <td>16:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>07:08:00</td>\n",
       "      <td>09:49:00</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>07:31:00</td>\n",
       "      <td>10:08:00</td>\n",
       "      <td>10:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19:00:00</td>\n",
       "      <td>19:59:00</td>\n",
       "      <td>19:05:00</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>19:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16:39:00</td>\n",
       "      <td>18:02:00</td>\n",
       "      <td>16:51:00</td>\n",
       "      <td>16:51:00</td>\n",
       "      <td>17:57:00</td>\n",
       "      <td>18:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10:39:00</td>\n",
       "      <td>14:21:00</td>\n",
       "      <td>10:05:00</td>\n",
       "      <td>10:56:00</td>\n",
       "      <td>13:38:00</td>\n",
       "      <td>13:41:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DepTime CRSArrTime CRSDepTime WheelsOff  WheelsOn   ArrTime\n",
       "0   13:53:00   15:01:00   14:00:00  14:02:00  14:39:00  14:44:00\n",
       "1   09:03:00   11:18:00   09:35:00  09:57:00  11:13:00  11:19:00\n",
       "2   06:37:00   08:55:00   06:43:00  06:54:00  08:22:00  08:38:00\n",
       "3   13:14:00   14:33:00   13:35:00  13:37:00  13:57:00  14:04:00\n",
       "4   08:26:00   10:04:00   08:36:00  08:52:00  09:59:00  10:09:00\n",
       "5   16:00:00   18:26:00   16:01:00  16:21:00  18:11:00  18:14:00\n",
       "6   16:14:00   18:56:00   16:15:00  16:43:00  18:55:00  18:59:00\n",
       "7   10:53:00   12:04:00   10:45:00  11:07:00  12:18:00  12:26:00\n",
       "8   06:24:00   07:51:00   06:37:00  07:08:00  07:45:00  07:49:00\n",
       "9   07:59:00   11:07:00   08:03:00  08:18:00  10:53:00  11:08:00\n",
       "10  15:41:00   17:03:00   15:36:00  15:53:00  16:51:00  16:59:00\n",
       "11  07:08:00   09:49:00   06:45:00  07:31:00  10:08:00  10:15:00\n",
       "12  19:00:00   19:59:00   19:05:00  19:15:00  19:31:00  19:39:00\n",
       "13  16:39:00   18:02:00   16:51:00  16:51:00  17:57:00  18:02:00\n",
       "14  10:39:00   14:21:00   10:05:00  10:56:00  13:38:00  13:41:00"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[hhmm].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 566924 entries, 0 to 583984\n",
      "Columns: 64 entries, Year to Div1LongestGTime\n",
      "dtypes: bool(5), category(3), float16(25), int16(8), int32(3), int8(1), object(19)\n",
      "memory usage: 153.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
