{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning combined datasets for each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After combining data for each year i will drop some columns after investigation which are \n",
    "\n",
    "**'DayOfWeek','DayofMonth','Month','Year'**  provide unuseful information as we can extract them fom flight date column\n",
    "'index',\n",
    "\n",
    "**'Div1LongestGTime','Div1WheelsOn','DivActualElapsedTime','LongestAddGTime','DivAirportLandings'**\n",
    "\n",
    "**'Tail_Number','Flight_Number_Reporting_Airline'**\n",
    "\n",
    "**'FirstDepTime','TotalAddGTime','Div1TotalGTime'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'D:\\on time data for airlines\\Quarter_Data\\2019_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1815633 entries, 0 to 1815632\n",
      "Data columns (total 51 columns):\n",
      "Unnamed: 0              int64\n",
      "Quarter                 int64\n",
      "FlightDate              object\n",
      "Reporting_Airline       object\n",
      "OriginAirportID         int64\n",
      "OriginCityMarketID      int64\n",
      "Origin                  object\n",
      "OriginCityName          object\n",
      "OriginStateName         object\n",
      "DestAirportID           int64\n",
      "DestCityMarketID        int64\n",
      "Dest                    object\n",
      "DestCityName            object\n",
      "DestStateName           object\n",
      "CRSDepTime              object\n",
      "DepTime                 object\n",
      "DepDelay                float64\n",
      "DepDelayMinutes         float64\n",
      "DepDel15                bool\n",
      "DepartureDelayGroups    float64\n",
      "DepTimeBlk              object\n",
      "TaxiOut                 float64\n",
      "WheelsOff               object\n",
      "WheelsOn                object\n",
      "TaxiIn                  float64\n",
      "CRSArrTime              object\n",
      "ArrTime                 object\n",
      "ArrDelay                float64\n",
      "ArrDelayMinutes         float64\n",
      "ArrDel15                bool\n",
      "ArrivalDelayGroups      float64\n",
      "ArrTimeBlk              object\n",
      "Cancelled               bool\n",
      "CancellationCode        float64\n",
      "Diverted                bool\n",
      "CRSElapsedTime          float64\n",
      "ActualElapsedTime       float64\n",
      "AirTime                 float64\n",
      "Flights                 int64\n",
      "Distance                float64\n",
      "DistanceGroup           int64\n",
      "CarrierDelay            float64\n",
      "WeatherDelay            float64\n",
      "NASDelay                float64\n",
      "SecurityDelay           float64\n",
      "LateAircraftDelay       float64\n",
      "DivReachedDest          bool\n",
      "DivArrDelay             float64\n",
      "DivDistance             float64\n",
      "Div1Airport             object\n",
      "Div1AirportID           float64\n",
      "dtypes: bool(5), float64(21), int64(8), object(17)\n",
      "memory usage: 645.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes preservation issues\n",
    "\n",
    "after converting columns into desired dtypes and send this dataframe into csv files using **to_csv** so file size is **487 MB** and then read it back we find memoryuseage increase to **645.9 MB** so we will solve this issue by converting csv files into other format next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop= ['Div1WheelsOn',\n",
    "      'DayOfWeek',\n",
    "      'index',\n",
    "      'DayofMonth',\n",
    "      'Div1LongestGTime',\n",
    "      'Tail_Number',\n",
    "      'Flight_Number_Reporting_Airline',\n",
    "      'DivActualElapsedTime',\n",
    "      'LongestAddGTime',\n",
    "      'DivAirportLandings',\n",
    "      'FirstDepTime',\n",
    "      'TotalAddGTime',\n",
    "      'Month',\n",
    "      'Div1TotalGTime',\n",
    "      'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.drop(dop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data \n",
    "\n",
    "after dropping unusefull columns we have to save the new dataframe but i have read from this [link](https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d) in towards data science which compare between different frmat for data and compare between them and after search on github i fond if i save data in **.csv** format i automatically upcast after we already downcast them so this will arise memory issues for further analysis due to out of memory issues i found this in this info [link](https://github.com/pandas-dev/pandas/issues/27749) so i decide to save data after conversion into **.msgpack** format which preserve data tyoes after conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_msgpack(r'D:\\on time data for airlines\\Quarter_Data\\2019_combined.msgpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's read our dataframe again with **read_msgpack** this time and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_msgpack(r'D:\\on time data for airlines\\Quarter_msg\\2019_combined.msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1815633 entries, 0 to 1815632\n",
      "Data columns (total 51 columns):\n",
      "Unnamed: 0              int64\n",
      "Quarter                 category\n",
      "FlightDate              object\n",
      "Reporting_Airline       object\n",
      "OriginAirportID         float16\n",
      "OriginCityMarketID      float32\n",
      "Origin                  object\n",
      "OriginCityName          object\n",
      "OriginStateName         object\n",
      "DestAirportID           float16\n",
      "DestCityMarketID        float32\n",
      "Dest                    object\n",
      "DestCityName            object\n",
      "DestStateName           object\n",
      "CRSDepTime              object\n",
      "DepTime                 object\n",
      "DepDelay                float16\n",
      "DepDelayMinutes         float16\n",
      "DepDel15                bool\n",
      "DepartureDelayGroups    category\n",
      "DepTimeBlk              object\n",
      "TaxiOut                 float16\n",
      "WheelsOff               object\n",
      "WheelsOn                object\n",
      "TaxiIn                  float16\n",
      "CRSArrTime              object\n",
      "ArrTime                 object\n",
      "ArrDelay                float16\n",
      "ArrDelayMinutes         float16\n",
      "ArrDel15                bool\n",
      "ArrivalDelayGroups      category\n",
      "ArrTimeBlk              object\n",
      "Cancelled               bool\n",
      "CancellationCode        category\n",
      "Diverted                bool\n",
      "CRSElapsedTime          float16\n",
      "ActualElapsedTime       float16\n",
      "AirTime                 float16\n",
      "Flights                 int8\n",
      "Distance                float16\n",
      "DistanceGroup           category\n",
      "CarrierDelay            float16\n",
      "WeatherDelay            float16\n",
      "NASDelay                float16\n",
      "SecurityDelay           float16\n",
      "LateAircraftDelay       float16\n",
      "DivReachedDest          bool\n",
      "DivArrDelay             float16\n",
      "DivDistance             float16\n",
      "Div1Airport             object\n",
      "Div1AirportID           float16\n",
      "dtypes: bool(5), category(5), float16(20), float32(2), int64(1), int8(1), object(17)\n",
      "memory usage: 351.5+ MB\n"
     ]
    }
   ],
   "source": [
    "my_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that after saving our data with **.msgpack** we success in preserving data types and memory usage now decreaced to half with total memory usage **351.5 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
